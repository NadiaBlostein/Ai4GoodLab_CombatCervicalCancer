{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out mean and std\n",
    "\n",
    "\n",
    "# import torch \n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# mean = 0.0\n",
    "# std = 0.0\n",
    "# for images, _ in loader:\n",
    "#     batch_samples = images.size(0) \n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "#     mean += images.mean(2).sum(0)\n",
    "#     std += images.std(2).sum(0)\n",
    "\n",
    "# mean /= len(loader.dataset)\n",
    "# std /= len(loader.dataset)\n",
    "\n",
    "# print(mean)\n",
    "# print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from PIL import ImageFile \n",
    "import pathlib\n",
    "import random \n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler \n",
    "import os\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(\"GPU Available: {}\".format(use_gpu))\n",
    "\n",
    "# input_folder = 'CervicalCancer/Additional /Type_2'\n",
    "# input_folder = 'CervicalCancer/CC_smallDataset'\n",
    "input_folder = 'CervicalCancer/Train'\n",
    "test_folder = 'CervicalCancer/Test'\n",
    "\n",
    "\n",
    "\n",
    "#lets check how many files are there in the path we defined\n",
    "# count = 0\n",
    "# for path in pathlib.Path(input_folder).iterdir():\n",
    "#     if path.is_file():\n",
    "#         count += 1\n",
    "# print(count)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose( [transforms.Resize((256,256)),\n",
    "#                                  transforms.CenterCrop(128),\n",
    "                                 transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5148, 0.4237, 0.4607), (0.1985, 0.1767, 0.1888))])\n",
    "\n",
    "\n",
    "# change from CIFAR: adding .ImageFolder\n",
    "# now, we can load\n",
    "trainset = datasets.ImageFolder(root=input_folder,\n",
    "                                           transform=transform)\n",
    "# testset = datasets.ImageFolder(root=test_folder,transform=transform)\n",
    "\n",
    "\n",
    "# split the validation \n",
    "valid_size = 0.15\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "# if we want to shuffle:\n",
    "shuffle = True\n",
    "if shuffle:\n",
    "    np.random.seed(random.randint(1,10))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32,sampler=train_sampler,\n",
    "                                            num_workers=2)\n",
    "\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(trainset, batch_size=32, sampler=valid_sampler,\n",
    "                                            num_workers=2)\n",
    "# test_loader = torch.utils.data.DataLoader(testset, batch_size=32,num_workers=2)\n",
    "\n",
    "\n",
    "# lets see what we have in the train loader\n",
    "# for i, data in enumerate(train_loader):\n",
    "#     # get the inputs; data is a list of [inputs, labels]\n",
    "#     print(data)\n",
    "#     inputs, labels = data\n",
    "#     print(f'this is input: {inputs},this is labels : {labels}')\n",
    "\n",
    "\n",
    "#check if the train, valid works\n",
    "# count = 0                                       \n",
    "# for i, data in enumerate(valid_loader):\n",
    "#     count +=1\n",
    "#     inputs, labels = data\n",
    "# print(f'this is the number of images in validation:{count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ec2-user/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "# Let's define a network\n",
    "\n",
    "#this is densenet network\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "#the followng is the CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add_module('cv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0, dilation=1))\n",
    "        self.net.add_module('rl1', nn.ReLU()) # activation functions don't change the size\n",
    "        self.net.add_module('bn1', nn.BatchNorm2d(num_features = 32))\n",
    "        self.net.add_module('cv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0, dilation=1))\n",
    "        self.net.add_module('rl2', nn.ReLU())\n",
    "        self.net.add_module('bn2', nn.BatchNorm2d(num_features = 32))\n",
    "        self.net.add_module('mp1', nn.MaxPool2d(kernel_size=2, stride=None, padding=0, dilation=1)) # choose 1 pixel from 2x2 matrix (spatial_dim/kernel_size) (reduce the size)\n",
    "        self.net.add_module('dp1', nn.Dropout2d(p=0.25))\n",
    "        self.net.add_module('fl1', nn.Flatten())\n",
    "        self.net.add_module('fc1', nn.Linear(in_features=1016064, out_features=128)) # 64 * spatial_dim_1 * spatial_dim_2 = (in_features)\n",
    "        self.net.add_module('rl3', nn.ReLU())                                     # spatial_dim_1 = 28; spatial_dim_2 = 28\n",
    "        self.net.add_module('dp2', nn.Dropout(p=0.5))\n",
    "        self.net.add_module('fc2', nn.Linear(in_features=128, out_features=3))\n",
    "        self.net.add_module('sm1', nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# chossing the model which in we want to feed the data \n",
    "\n",
    "# model = Net().to(device) ##this is CNN\n",
    "model = model.to(device)\n",
    "\n",
    "# Let's define an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # adjust the learning rate \n",
    "\n",
    "# Let's define a Loss function\n",
    "lossfun = nn.NLLLoss()  # Use nn.CrossEntropyLoss with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MELTEM: output file for results\n",
    "logfile = open('./logfile_{}.txt'.format(\"CC_Resnet12_20epochs\"), 'a')\n",
    "\n",
    "#lets train the model\n",
    "\n",
    "# # Training\n",
    "def train(epoch,loader,net):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = lossfun(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()   \n",
    "\n",
    "        # MELTEM:removed\n",
    "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        #MELTEM:added\n",
    "        msg = 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "#         progress_bar(batch_idx, len(trainloader), msg)\n",
    "        logfile.write('Train epoch {}. {}\\n'.format(epoch, msg))\n",
    "    \n",
    "    return train_loss, 100.*correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets implement validation check \n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "def valid(epoch,valid_loader,net):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = lossfun(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            #MELTEM:removed\n",
    "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "            #MELTEM:added\n",
    "            msg = 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "#             progress_bar(batch_idx, len(testloader), msg)\n",
    "            logfile.write('Test epoch {}. {}\\n'.format(epoch, msg))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),   \n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.t7')   \n",
    "        best_acc = acc\n",
    "        \n",
    "    return test_loss, acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8edffff90357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mt_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mt_loss_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2543fe944a33>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, loader, net)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Loss: %.3f | Acc: %.3f%% (%d/%d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#         progress_bar(batch_idx, len(trainloader), msg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlogfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train epoch {}. {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# for epoch in range(start_epoch, start_epoch+max_nbr_epoch):\n",
    "t_loss_a = []\n",
    "v_loss_a = []\n",
    "temp = []\n",
    "count = 0 \n",
    "for epoch in range(1,2):\n",
    "    temp.append(count)\n",
    "    count+=1\n",
    "    t_loss, t_accuracy = train(epoch,train_loader,model)\n",
    "    v_loss, v_accuracy = valid(epoch,valid_loader,model)\n",
    "    t_loss_a.append(t_loss)\n",
    "    v_loss_a.append(v_loss)\n",
    "    \n",
    "plt.plot(temp, t_loss_a, label='train')\n",
    "plt.plot(temp, v_loss_a, label='valid')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader):\n",
    "\n",
    "  # evaluating\n",
    "  model.eval()\n",
    "\n",
    "  test_accuracy = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "\n",
    "      if use_gpu:\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "      output = model(data)\n",
    "\n",
    "      test_accuracy += (output.argmax(-1) == target).float().sum().item()\n",
    "  \n",
    "  test_accuracy /= len(testloader.dataset)\n",
    "  print(\"Test set accuracy: {}\".format(test_accuracy ))\n",
    "  \n",
    "  return test_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-30f4e277ba4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483\n",
      "1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#attempting confusion matrix \n",
    "\n",
    "print(len(trainset))\n",
    "print(len(trainset.targets))\n",
    "\n",
    "#getting the prediction on a tensor\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(trainset, batch_size=10000)\n",
    "    train_preds = get_all_preds(model,prediction_loader)\n",
    "\n",
    "preds_correct = get_num_correct(train_preds, trainset.targets)\n",
    "\n",
    "# print('total correct:', preds_correct)\n",
    "# print('accuracy:', preds_correct / len(trainset))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
